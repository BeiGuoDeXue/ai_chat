[1.2.7]
服务器：
1. 优化代码结构
客户端：
1. 增加wifi状态监控
2. 调整websocket发送任务优先级为6、调整websocket接收任务优先级为6，这里使用时需要修改wifi_station.h的代码

[1.2.6]
服务器:
1. 优化部分日志打印
客户端:
1. 增加websocket重连机制，当websocket连接断开时，自动重连，创建任务5s检测一次
2. 增加websocket心跳机制，当websocket连接断开时，自动重连

[1.2.5]
服务器:
重构服务器端，各个功能拆分到单独的脚本，模块化导入
1. vad拆分到vad_detector.py
2. 音频播放拆分到audio_player.py
3. 音频录制拆分到audio_recorder.py
4. 音频分析拆分到audio_analyzer.py
5. 语音识别、合成拆分到speech_service.py
6. 音频数据保存拆分到audio_saver.py
客户端：
去除mic_data_handle的过滤处理，使语音检测更准确

[1.2.4]
服务器：
1. 接收客户端esp32上传的数据协议更新
2. 增加play_audio，可以实时播放客户端上传的音频数据
3. 修复vad检测处理数据慢的问题，一次get_data_process处理所有的缓存数据
客户端：
1. 读取音频数据优化，采用32位精度读取数据，支持远距离读取音频
2. 发送到服务器数据改为json格式
3. 修复由于网络问题引起的分包，导致客户端接收不全的问题

[1.2.3]
服务器：
1. 增加流控制，避免客户端的缓存满了
客户端：
1. 增加流控制，当缓冲区大于75%时，给服务器发消息，暂停数据下发
2. 增加喇叭的音量调节功能

[1.2.2]
客户端：
1. 优化音频播放策略，大量数据缓存在未解码前，播放音频的ring buffer达到一定数量后停止解码，后面再解码
2. 和服务器通讯采用json格式，避免服务器处理struct时不方便
服务器：
1. 采用json格式和客户端通讯
2. 下发数据时，一次下发不大于1024字节，大概6包数据
其他：
1. 增加convert_pm3_to_pcm.py，可以播放音乐，增加秋风音乐

[1.2.1]
1. 解决任务监控的不准的bug
2. 解决麦克风数据异常的问题
3. 音频输入、输出的任务去掉延时，因为是阻塞式读取，不占cpu
4. 音频输入、输出的dma大小修复
5. 增加.env，key从.env读取

[1.2.0]
1. 优化是否有人在说话的检测逻辑，使用webrtcvad，目前对话还可以
2. 接下来解决麦克风问题

[1.1.1]
1. 添加同事的大语言模型接口
2. 大语言模型接口化
3. 优化判断语音结束的逻辑

[1.1.0]
服务器：
1. 新增火山云ai语音接口
2. 新增电脑麦克风读取音频，然后实现了通过火山云的对话，esp32播放对话的内容
客户端：
1. 化esp32的语音播放流畅度
2. 解决opus编码crash问题，使用psram存储大块数据

[commit eb8439c]
1. 优化ring buffer处理
2. 添加线程cpu占用率、堆栈占用情况统计
3. 给不同的线程分配不同的核

[commit 1ef3a2b]
1. 修复opus编码失败问题，由于编码需要27K的空间，导致每次编码失败

[commit 21ae0e0]
1. 音频解码线程之前通讯改为ring buffer
2. 和服务器通讯改为大包包含小包的协议方式
3. 音频数据压缩还有点问题

[1.0.0]
1. 解决opus解码失败问题，原因是解码的包和编码的包必须是同一个包
2. 喇叭可以正常播放服务器下发的语音

[commit 279cb36]
1. 第一版基于idf的工程
2. 已经实现wifi、websocket
3. opus编解码还有点不稳定，需要继续调试
4. 强制推上去覆盖原有arduino工程